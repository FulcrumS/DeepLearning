{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**深度卷积网络一开始面临的最主要的问题是梯度消失和梯度爆炸。**\\\n",
    "那什么是梯度消失和梯度爆炸呢？\n",
    "所谓**梯度消失**，就是在深层神经网络的训练过程中，计算得到的梯度越来越小，使得权值得不到更新的情形，这样算法也就失效了。\\\n",
    "而**梯度爆炸**是指在神经网络训练过程中梯度变得越来越大，权值得到疯狂更新的情形，这样算法得不到收敛，模型也就失效了。当然，其间通过设置 relu 和归一化激活函数层等手段使得我们很好的解决这些问题。\\\n",
    "但当我们将网络层数加到更深时却发现训练的准确率在逐渐降低。这种并不是由过拟合造成的神经网络训练数据识别准确率降低的现象我们称之为**退化**（degradation）。其原因可能是：`随着网络的加深，一些层通常是没有必要出现的，如果训练好的参数随着后面的网络扰动，会被类似于白噪音的问题使参数重新偏移变差。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T12:45:19.564534Z",
     "start_time": "2020-06-05T12:45:19.525990Z"
    }
   },
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605204500590.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)\n",
    "\n",
    "> 由上图我们可以看到 56 层的普通卷积网络不管是在训练集还是测试集上的训练误差都要高于 20 层的卷积网络。是个典型的退化现象。\n",
    "> \n",
    "> 这退化问题不解决，咱们的深度学习就无法 go deeper. 于是何凯明等一干大佬就发明了残差网络 ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  何凯明给出的创新在于给网络之间添加一个捷径（shortcuts）或者也叫跳跃连接（skip connection），这使得捷径之间之间的网络能够学习一个恒等函数，使得在加深网络的情形下训练效果至少不会变差。\n",
    "> \n",
    "> 残差块的基本结构如下：\n",
    "\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605204714659.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 你可能会问凭什么加了一条从输入到输出的捷径网络就能防止退化训练更深层的卷积网络？或是是说残差网络为什么能有效？我们将上述残差块的两层输入输出符号改为 和 ，相应的就有：\n",
    "$$a^{[l+2]}=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]}) (g=relu)\\\\\n",
    "在网络中加入 L2 正则化进行权值衰减或者其他情形下，l+2 层的权值 W 是很容易衰减为零的，假设b=0就有 \\\\\n",
    "恒等式:a^{[l+2]}=a^{[l]}+min$$\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605230303544.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)\n",
    "> 看我画的红圈圈，如果是**plain网络，是没有1的，那么梯度是非常小的，很多非常小的梯度链式相乘变得更小，梯度消失**。因为有了**short cut加上了1，梯度变成比1大一点点(梯度为1+min_num)，在这个环节上保持了链式梯度的稳定性。**\n",
    "就是说加上short cut的前后，在网络退化问题上，由输入输出较大的线性变化，变成了基本相当的恒等映射。\n",
    "如果加上short cut之后变成完全恒等的映射，梯度变成1，那么不加任何模块也能达到这个效果。\n",
    "实际上，**虽然F(x)->0，但F(x)并不等于0，**,用吴恩达的话说：\\\n",
    "**当然我们的目标不仅仅是保持网络效率，还要提升它的效率。想象一下，如果这些（残差模块中的）隐层单元学到一些有用信息，那么它可能比学习恒等函数表现得更好。\n",
    "加上残差模块，能确定网络性能不会受到（较大）影响（因F(x)->0），很多时候甚至可以提高效率（F(x)虽然很小，还是学习到了新的特征），或者说至少不会降低网络效率。因此创建类似残差网络可以提升性能。**\n",
    ">> **Plain+残差模块**：梯度为1+min_num，基本恒等映射，但就是（基本恒等映射-完全恒等映射）的F(x)可能学习到了有用的信息，使得网络进一步优化。\\\n",
    ">> **不加F(x)，只加X**：梯度为1，完全恒等映射，对网络优化没有贡献。\\\n",
    ">> **不加X的平凡网络**：梯度为min_num，加强了梯度消失；映射的线性变化很大，过大，可能把已经优化好的参数又改变了，是网络退化的原因。\\\n",
    ">> **把一个深度网络中的层都搞成残差模块**：梯度都变成了1+min_num，链式乘起来会发生梯度爆炸的事件，会导致训练不收敛，因此必须中间有几个min_num，以保证最初几层的梯度参数在一个合理范围之内。\n",
    "> 由很多个残差块组成的残差网络如下图右图所示：\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605205317804.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 残差网络 resnet50 的 keras 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要实现一个残差块，关键在于实现一个跳跃连接。实际处理中跳跃连接会随着残差块输入输出大小的不同而分为两种。一种是输入输出一致情况下的 **第一种残差块**`Identity Block`，另一种则是输入输出不一致情形下的 **第二种残差块**`Convolutional Block`，顾名思义，就是跳跃连接中包含卷积操作，用来使得输入输出一致。且看二者的 keras 实现方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:22:19.476421Z",
     "start_time": "2020-06-05T13:22:14.784620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D,BatchNormalization,\\\n",
    "Activation,Add,Input,ZeroPadding2D,MaxPool2D,AveragePooling2D,Flatten,Dense,Lambda\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model \n",
    "import numpy as np \n",
    "from keras.datasets import cifar10\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恒等块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605205655575.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> kernel_size、stride都为(1,1)这样深度大小不变\\\n",
    "> 即使kernel_size=(f,f)，padding='same'也保证深度大小与输入相同\\\n",
    "> BatchNormalization:批量归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:22:19.495416Z",
     "start_time": "2020-06-05T13:22:19.479411Z"
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X,f,filters,stage,block):\n",
    "    conv_name=f\"res{stage}{block}_branch\"\n",
    "    bn_name=f\"bn{stage}{block}_branch\"\n",
    "    f1,f2,f3=filters\n",
    "    X_shortcut=X \n",
    "#     第一个组件\n",
    "    X=Conv2D(filters=f1,kernel_size=(1,1),strides=(1,1),padding='valid',name=conv_name+\"2a\",kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name+\"2a\")(X)\n",
    "    X=Activation('relu')(X)\n",
    "#     第二个组件 \n",
    "    X=Conv2D(f2,kernel_size=(f,f),strides=(1,1),padding='same',name=conv_name+\"2b\",kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name+\"2b\")(X)\n",
    "    X=Activation('relu')(X) \n",
    "#     第三个组件 \n",
    "    X=Conv2D(f3,kernel_size=(1,1),strides=(1,1),padding='valid',name=conv_name+\"2c\",kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name+\"2c\")(X)\n",
    "#     关键一步 \n",
    "    X=Add()([X,X_shortcut])\n",
    "    X=Activation('relu')(X)\n",
    "    return X \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T10:03:05.289461Z",
     "start_time": "2020-06-05T10:03:05.280479Z"
    }
   },
   "source": [
    "## 卷积块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605205744580.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:22:19.516420Z",
     "start_time": "2020-06-05T13:22:19.499418Z"
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X,f,filters,stage,block,s=2):\n",
    "    conv_name=f\"res{stage}{block}_branch\"\n",
    "    bn_name=f\"bn{stage}{block}_branch\"\n",
    "    f1,f2,f3=filters\n",
    "    X_shortcut=X \n",
    "#     第一个组件\n",
    "    X=Conv2D(f1,(1,1),strides=(s,s),name=conv_name+\"2a\",padding='valid',kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name+\"2a\")(X)\n",
    "    X=Activation('relu')(X) \n",
    "#     第二个组件 \n",
    "    X=Conv2D(f2,(f,f),strides=(1,1),name=conv_name+\"2b\",padding='same',kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name+\"2b\")(X)\n",
    "    X=Activation('relu')(X) \n",
    "#     第三个组件 \n",
    "    X=Conv2D(f3,(1,1),strides=(1,1),name=conv_name+\"2c\",padding='valid',kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=bn_name+\"2c\")(X)\n",
    "#     改造 X_shortcut \n",
    "    X_shortcut=Conv2D(f3,(1,1),strides=(s,s),name=conv_name+\"1\",kernel_initializer=glorot_uniform(0))(X_shortcut)\n",
    "    X_shortcut=BatchNormalization(axis=3,name=bn_name+\"1\")(X_shortcut)\n",
    "#     关键一步 \n",
    "    X=Add()([X,X_shortcut])\n",
    "    X=Activation('relu')(X)\n",
    "    return X \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 残差网络 resnet50 的 keras 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet50共有四组block,每组分别是 3 4 6 3个block,每个block里面有三个卷积层\n",
    "另外最开始都有一个单独的卷积层\n",
    "> （3+4+6+3）*3+1=49 层卷积\\\n",
    "49+最后1层全连接\n",
    "\n",
    "所以共有50层网络（有待学习的参数，pooling层不需要参数）\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605215959924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200605205823798.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:22:19.542426Z",
     "start_time": "2020-06-05T13:22:19.519422Z"
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64,64,3),classes=6):\n",
    "    X_input=Input(input_shape)\n",
    "    X=ZeroPadding2D((3,3))(X_input)\n",
    "#     stage:1\n",
    "    X=Conv2D(filters=64,kernel_size=(7,7),strides=(2,2),name=\"conv\",kernel_initializer=glorot_uniform(0))(X)\n",
    "    X=BatchNormalization(axis=3,name=\"bn\")(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPool2D(pool_size=(3,3),strides=(2,2))(X) \n",
    "#     stage:2 \n",
    "    X=convolutional_block(X,f=3,filters=[64,64,256],stage=2,block='a',s=1)\n",
    "    X=identity_block(X,f=3,filters=[64,64,256],stage=2,block='b')\n",
    "    X=identity_block(X,f=3,filters=[64,64,256],stage=2,block='c')\n",
    "#     stage:3\n",
    "    X=convolutional_block(X,f=3,filters=[128, 128, 512],stage=3,block='a',s=1)\n",
    "    X=identity_block(X,f=3,filters=[128, 128, 512],stage=3,block='b')\n",
    "    X=identity_block(X,f=3,filters=[128, 128, 512],stage=3,block='c')\n",
    "    X=identity_block(X,f=3,filters=[128, 128, 512],stage=3,block='d')\n",
    "#     stage:4\n",
    "    X=convolutional_block(X,f=3,filters=[256,256,1024],stage=4,block='a',s=2) \n",
    "    X=identity_block(X,f=3,filters=[256,256,1024],stage=4,block='b')\n",
    "    X=identity_block(X,f=3,filters=[256,256,1024],stage=4,block='c')\n",
    "    X=identity_block(X,f=3,filters=[256,256,1024],stage=4,block='d')\n",
    "    X=identity_block(X,f=3,filters=[256,256,1024],stage=4,block='e')\n",
    "    X=identity_block(X,f=3,filters=[256,256,1024],stage=4,block='f')\n",
    "#     stage:5 \n",
    "    X=convolutional_block(X,f=3,filters=[512,512,2048],stage=5,block='a',s=2)\n",
    "    X=identity_block(X,f=3,filters=[512,512,2048],stage=5,block='b')\n",
    "    X=identity_block(X,f=3,filters=[512,512,2048],stage=5,block='c')\n",
    "#     AVGPOOL \n",
    "    X=AveragePooling2D(pool_size=(2,2),padding='same')(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(classes,activation='softmax',name=f'fc{classes}',kernel_initializer=glorot_uniform(0))(X)\n",
    "#     Model\n",
    "    model=Model(inputs=X_input,outputs=X,name='ResNet50')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:23:27.073814Z",
     "start_time": "2020-06-05T13:22:19.546429Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8d91270d1830>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting fashion-mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting fashion-mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting fashion-mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting fashion-mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\software\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/12\n",
      "  900/55000 [..............................] - ETA: 45:01 - loss: 2.1466 - accuracy: 0.2756"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8d91270d1830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X_train,y_train,X_test,y_test=cifar10.load_data()\n",
    "\n",
    "# X_test=to_categorical(X_test,10)\n",
    "# y_test=to_categorical(y_test,10)\n",
    "mnist=input_data.read_data_sets('fashion-mnist/',one_hot=True)\n",
    "X_train,X_test=mnist.train.images,mnist.test.images \n",
    "X_train=X_train.reshape(len(X_train),28,28,-1)\n",
    "X_test=X_test.reshape(len(X_test),28,28,-1)\n",
    "y_train=mnist.train.labels\n",
    "y_test=mnist.test.labels \n",
    "input_shape=X_train.shape[1:]\n",
    "classes=10 \n",
    "model=ResNet50(input_shape,classes)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=12,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:26:26.375874Z",
     "start_time": "2020-06-05T13:26:26.330850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e0028b3036cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PATH\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpathsep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'D:\\software\\Graphviz2.38\\bin'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multilayer_perceptron_graph.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydotplus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydotplus\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# to check the pydotplus/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         raise OSError(\n",
      "\u001b[1;32mD:\\software\\Python37\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "import os     \n",
    "os.environ[\"PATH\"] += os.pathsep + 'D:\\software\\Graphviz2.38\\bin'\n",
    "plot_model(model,to_file='multilayer_perceptron_graph.png',show_shapes=True,show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bita5f53f9b60c0490aa934da503dc99db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
