{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相较于 CNN 在图像识别和检测方面的广泛应用，**基于序列模型的 RNN 的应用方面则是语音识别、文本翻译和自然语言处理等其他更为激动人心的领域**。所以，正如 CNN 在计算机视觉中的应用一样，在 RNN 中笔者将重点关注其在自然语言处理的应用与研究。\n",
    "![请添加图片描述](https://img-blog.csdnimg.cn/20200615232011296.png)\n",
    "**RNN 使用场景**\n",
    ">  相较于 DNN 和 CNN，RNN 网络结构有什么特别之处？它与前两者又有哪些不一样的结构设计？\n",
    ">> 在对 RNN 的结构进行深入了解之前，我们必须对使用 RNN 面临的问题场景进行梳理。假设我们在进行语音识别时，**给定了一个输入音频片段 x，要求我们输出一个文本片段 y，其中输入 x 是一个按照时间播放的音频片段，y 是一个按照顺序排列的单词组成的一句话，所以在 RNN 中我们的输入输出都是序列性质的**。针对这样的输入输出（x,y）的有监督学习，最适合的神经网络结构就是循环神经网络。为什么循环神经网络就最适用这种场景？\n",
    "\n",
    "> **在正式介绍 RNN 前，我们先来看下对于序列问题使用常规的神经网络看看会有什么问题。**\n",
    "\n",
    "> 假设我们现在需要对输入的一段话识别其中每个单词是否是人名，即输入是一段文本序列，输出是一个每个单词是否是人名的序列。假设这段话有9个单词，我们将其转化为 9 个 one-hot 向量输入到标准神经网络中去，经过一些隐藏层和激活函数得到最终 9 个值为 0/1 的输出。但这样做的问题有两个：\n",
    "\n",
    ">> 一是输入输出的长度是否相等以及输入大小不固定的问题。在语音识别问题中，输入音频序列和输出文本序列很少情况下是长度相等的，普通网络难以处理这种问题。\n",
    "\n",
    ">> 二是普通神经网络结构不能共享从文本不同位置上学到的特征，简单来说就是如果神经网络已经从位置 1 学到了 louwill 是一个人名，那么如果 louwill 出现在其他位置，神经网络就可以自动识别到它就是已经学习过的人名，这种共享可以减少训练参数和提高网络效率，普通网络不能达到这样的目的。\n",
    "\n",
    "所以直观上看，普通神经网络和循环神经网络的区别如下图所示：\n",
    "![请添加图片描述](https://img-blog.csdnimg.cn/20200615232011283.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN 结构**\n",
    "> 假设我们将一个句子输入 RNN，第一个输入的单词就是 x1, 我们将 x1 输入到神经网络，经过隐藏层得到输出判断其是否为人名，即输出为 y1。同时网络初始化隐藏层激活值，并在隐藏层中结合输入 x1 进行激活计算传入到下一个时间步。当输入第二个单词 x2 的时候，除了使用 x2 预测输出 y2 之外，当前时间步的激活函数会基于上一个时间步的进行激活计算，即第二个时间步利用了第一个时间步的信息。这便是循环（Recurrent）的含义。如此下去，一直到网络在最后一个时间步输出 yn 和 激活值 an。所以在每一个时间步中，RNN 传递一个激活值到下一个时间步中用于计算。\n",
    "![请添加图片描述](https://img-blog.csdnimg.cn/20200615232011279.png)\n",
    "> 上图便是循环神经网络的基本结构。左边是一个统一的表现形式，右边则是左边的展开图解。在这样的循环神经网络中，当我们在预测 yt 时，不仅要使用 xt 的信息，还要使用 xt-1 的信息，因为在横轴路径上的隐藏层激活信息得以帮助我们预测 yt。\n",
    "> 所以， RNN 单元结构通常需要两次计算，**一次是隐藏层隐变量激活函数的计算，一个是结合隐变量和输入的计算。** 一个 RNN 单元和两次计算如下图所示：\n",
    "![请添加图片描述](https://img-blog.csdnimg.cn/20200615232011298.png)\n",
    "\n",
    "当多个 RNN 单元组合到一起便是 RNN 结构：\n",
    "![请添加图片描述](https://img-blog.csdnimg.cn/20200615232011270.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##       定义 sigmoid 和 softmax 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T15:28:44.711884Z",
     "start_time": "2020-06-15T15:28:44.701866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4647, 1.6273, 1.5951, 1.5470, 1.5285],\n",
       "        [1.5339, 1.4635, 1.8900, 1.3998, 1.4948],\n",
       "        [1.6439, 1.7627, 1.5095, 1.5058, 1.8211]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  \n",
    "def softmax(x):\n",
    "    x=(x-torch.max(x)).exp() \n",
    "    return x/x.sum(dim=1,keepdim=True)\n",
    "def sigmoid(x):\n",
    "    return 1/1+torch.exp(-x)\n",
    "x=torch.rand((3,5))\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义 RNN 单元结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T15:28:44.728873Z",
     "start_time": "2020-06-15T15:28:44.713880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnn_cell_forward(xt,a_prev,params):\n",
    "    wa=params['wa']\n",
    "    wx=params['wx']\n",
    "    wy=params['wy']\n",
    "    ba=params['ba']\n",
    "    by=params['by']\n",
    "    a_next=torch.tanh(torch.matmul(xt,wx)+torch.matmul(a_prev,wa)+ba)\n",
    "    yt_pred=softmax(torch.matmul(a_next,wy)+by)\n",
    "    cache=(xt,a_prev,params)\n",
    "    return a_next,yt_pred,cache\n",
    "xt=torch.rand((3,6))\n",
    "a_prev=torch.rand((3,5))\n",
    "wa=torch.rand((5,5))\n",
    "wx=torch.rand((6,5)) \n",
    "ba=torch.rand((1,5))\n",
    "wy=torch.rand((5,2))\n",
    "by=torch.rand((1,2))\n",
    "params={'wa':wa,'wx':wx,'ba':ba,'wy':wy,'by':by}\n",
    "a_next,yt_pred,cache=rnn_cell_forward(xt,a_prev,params)\n",
    "a_next.size() ,yt_pred.size() \n",
    "# yt_pred.sum(dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    基于 RNN 单元构建 RNN 网络结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T15:28:44.752878Z",
     "start_time": "2020-06-15T15:28:44.730873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0.4461, 0.1863, 0.8687, 0.0956, 0.5994, 0.6879],\n",
       "          [0.1863, 0.4802, 0.8571, 0.8659, 0.7129, 0.5296],\n",
       "          [0.6390, 0.2908, 0.6040, 0.3276, 0.2229, 0.5827]]),\n",
       "  tensor([[0.9962, 0.9745, 0.9974, 0.9883, 0.9851],\n",
       "          [0.9994, 0.9930, 0.9990, 0.9947, 0.9993],\n",
       "          [0.9988, 0.9904, 0.9977, 0.9874, 0.9947]]),\n",
       "  {'wa': tensor([[0.1900, 0.7057, 0.5123, 0.4440, 0.1618],\n",
       "           [0.9847, 0.0175, 0.6940, 0.3380, 0.3042],\n",
       "           [0.9820, 0.3948, 0.7807, 0.0740, 0.9785],\n",
       "           [0.0327, 0.6639, 0.0110, 0.0726, 0.3150],\n",
       "           [0.9289, 0.4353, 0.4073, 0.5214, 0.8053]]),\n",
       "   'wx': tensor([[0.4280, 0.7754, 0.6107, 0.1731, 0.6296],\n",
       "           [0.6651, 0.0597, 0.1774, 0.2797, 0.2999],\n",
       "           [0.2733, 0.4996, 0.7758, 0.5398, 0.1028],\n",
       "           [0.3013, 0.1577, 0.7483, 0.6863, 0.7298],\n",
       "           [0.1057, 0.7049, 0.9643, 0.5543, 0.5266],\n",
       "           [0.9915, 0.0670, 0.2047, 0.0556, 0.4298]]),\n",
       "   'ba': tensor([[0.8890, 0.2454, 0.5130, 0.7851, 0.4866]]),\n",
       "   'wy': tensor([[0.8922, 0.0175],\n",
       "           [0.6153, 0.6413],\n",
       "           [0.8316, 0.2355],\n",
       "           [0.7354, 0.8442],\n",
       "           [0.9472, 0.6277]]),\n",
       "   'by': tensor([[0.6011, 0.0221]])})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnn_forward(x,a0,params):\n",
    "    l_x,w_x,n_x=x.shape\n",
    "    ba,wy=params['ba'],params['wy']\n",
    "    a_next=a0\n",
    "    a=torch.zeros((l_x,ba.shape[1],n_x))\n",
    "    yt=torch.zeros((l_x,wy.shape[1],n_x))\n",
    "    caches=[[] for _ in range(n_x)]\n",
    "    for t in range(n_x):\n",
    "        a_next,yt_pred,cache=rnn_cell_forward(x[...,t],a_next,params)\n",
    "        a[...,t]=a_next \n",
    "        yt[...,t]=yt_pred\n",
    "        caches[t]+=[cache] \n",
    "    caches=(caches,x)\n",
    "    return a,yt,caches\n",
    "\n",
    "xt=torch.rand((3,6,7))\n",
    "a0=torch.rand((3,5))\n",
    "wa=torch.rand((5,5))\n",
    "wx=torch.rand((6,5)) \n",
    "ba=torch.rand((1,5))\n",
    "wy=torch.rand((5,2))\n",
    "by=torch.rand((1,2))\n",
    "params={'wa':wa,'wx':wx,'ba':ba,'wy':wy,'by':by}     \n",
    "a,yt,caches=rnn_forward(xt,a0,params)\n",
    "a.size(),yt.size() \n",
    "caches[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bita5f53f9b60c0490aa934da503dc99db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
