{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet import nd\n",
    "from mxnet import autograd\n",
    "def transform(data,label):\n",
    "    return data.astype('float32')/255,label.astype('float32')\n",
    "minist_train=gluon.data.vision.FashionMNIST(root='fashion-mnist/',train=True,transform=transform)\n",
    "minist_test=gluon.data.vision.FashionMNIST(root='fashion-mnist/',train=False,transform=transform)\n",
    "batch_size=256 \n",
    "train_data=gluon.data.DataLoader(minist_train,batch_size=batch_size,shuffle=True)\n",
    "test_data=gluon.data.DataLoader(minist_test,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd \n",
    "num_inputs,num_hidden ,num_outputs=28*28,256,10 \n",
    "weight_scale=.01 \n",
    "'''\n",
    "loc:float\n",
    "　　概率分布的均值，对应着整个分布的中心center\n",
    "scale:float\n",
    "　　概率分布的标准差，对应于分布的宽度，scale越大越矮胖，scale越小，越瘦高\n",
    "'''\n",
    "w1 ,b1 = nd.random_normal(shape=(num_inputs,num_hidden),scale=weight_scale),nd.zeros(num_hidden)\n",
    "w2 ,b2 = nd.random_normal(shape=(num_hidden,num_outputs),scale=weight_scale),nd.zeros(num_outputs)\n",
    "params = [w1,b1,w2,b2]\n",
    "for param in params:\n",
    "    param.attach_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在两层隐含层间定义relu激活函数，使模型可拟合非线性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return nd.maximum(X,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型，全连接+Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X=X.reshape((-1,num_inputs))\n",
    "    h1=relu(nd.dot(X,w1)+b1)\n",
    "    output=nd.dot(h1,w2)+b2 \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax+交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义精确度和优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output,label):\n",
    "    return nd.mean(output.argmax(axis=1)==label).asscalar()\n",
    "def evaluate_accuracy(test_data,net):\n",
    "    loss=0.\n",
    "    for data,label in test_data:\n",
    "        output=net(data) \n",
    "        loss+=accuracy(output,label)\n",
    "    return loss/len(test_data)\n",
    "def SGD(params,lr):\n",
    "    for param in params:\n",
    "        param[:]=param-lr*param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss:0.358499..,train_accuracy:0.871941,test_accuracy:0.021719..\n",
      "epoch 2,loss:0.350339..,train_accuracy:0.873986,test_accuracy:0.021743..\n",
      "epoch 3,loss:0.343806..,train_accuracy:0.875770,test_accuracy:0.021934..\n",
      "epoch 4,loss:0.338015..,train_accuracy:0.877438,test_accuracy:0.021936..\n"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd\n",
    "epochs=4\n",
    "learning_rate=.1\n",
    "for e in range(1,epochs+1):\n",
    "    train_loss,train_acc=0.,0. \n",
    "    for data,label in train_data:\n",
    "        with autograd.record():\n",
    "            output=net(data)\n",
    "            loss=softmax_cross_entropy(output,label)\n",
    "        loss.backward()\n",
    "        SGD(params,learning_rate/batch_size)\n",
    "        train_loss+=nd.mean(loss).asscalar()\n",
    "        train_acc+=accuracy(output,label)\n",
    "    test_acc=evaluate_accuracy(test_data,net)\n",
    "    print('epoch %d,loss:%f..,train_accuracy:%f,test_accuracy:%f..'%(e,train_loss/len(train_data),train_acc/len(train_data),\n",
    "                                                                    test_acc/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(784, 256), (256,), (256, 10), (10,)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package d2lzh:\n",
      "\n",
      "NAME\n",
      "    d2lzh\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    utils\n",
      "\n",
      "DATA\n",
      "    VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', '...\n",
      "    VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0...\n",
      "\n",
      "VERSION\n",
      "    0.8.11\n",
      "\n",
      "FILE\n",
      "    d:\\software\\python3.7\\lib\\site-packages\\d2lzh\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import d2lzh as d2l\n",
    "help(d2l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python37264bit976359a467c3400289726740d00d4381"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
