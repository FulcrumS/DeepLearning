{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 强化学习跟此前的监督学习有着本质的区别： **\n",
    "> 监督学习是**训练模型特征到标签的映射关系**，而强化学习的学习过程却是一种**从无到有的过程**。简单来说，强化学习是让计算机实现从一开始什么都不懂，经过**不断尝试和试错找到规律达到目的**这样的一个过程。强化学习的主体与环境基于离散的时间步长相作用。在每一个时间 t，主体接收到一个观测Ot，通常其中包含奖励Rt。然后，它从允许的集合中选择一个动作At，然后送出到环境中去。环境则变化到一个新的状态 St+1，然后决定了和这个变化  (St,At,St+1)相关联的奖励Rt+1。**强化学习主体的目标，是得到尽可能多的奖励**。**主体选择的动作是其历史的函数，它也可以选择随机的动作。** 可以看到**状态(State)、动作(Action)和奖励(Reward)**是强化学习的三个核心概念。\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200601102849744.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**传统的强化学习算法**\n",
    "> Q-Learning算法、Sarsa算法、Policy Gradients算法、蒙特卡洛树搜索等算法。\n",
    "\n",
    "**当下结合了深度学习的强化学习算法**\n",
    "> 深度Q网络(DQN)，以及结合神经网络之后的深度强化学习这一整个领域。\n",
    "\n",
    "**深度强化学习的核心框架：**\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/2020060110320239.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:22:42.037986Z",
     "start_time": "2020-06-01T02:22:42.033984Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "N_STATES=6\n",
    "ACTIONS=[\"left\",\"right\"]\n",
    "EPSILON=.9 \n",
    "ALPHA=.1 \n",
    "GAMMA=.9\n",
    "MAX_EPISODES=13 \n",
    "FRESH_TIME=.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:22:42.051704Z",
     "start_time": "2020-06-01T02:22:42.039694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left  right\n",
       "0   0.0    0.0\n",
       "1   0.0    0.0\n",
       "2   0.0    0.0\n",
       "3   0.0    0.0\n",
       "4   0.0    0.0\n",
       "5   0.0    0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_table(n_states,actions):\n",
    "    q_table=pd.DataFrame(np.zeros((n_states,len(actions))),columns=actions)\n",
    "    return q_table\n",
    "q_table=build_table(N_STATES,ACTIONS)\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:22:42.063722Z",
     "start_time": "2020-06-01T02:22:42.051704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_action(S,q_table):\n",
    "    action_choice=q_table.iloc[S,:]\n",
    "    if np.random.rand()>EPSILON or action_choice.all()==0:\n",
    "        action=np.random.choice(ACTIONS)\n",
    "    else:\n",
    "        action=ACTIONS[action_choice.argmax()]\n",
    "    return action\n",
    "choose_action(3,q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:22:42.071710Z",
     "start_time": "2020-06-01T02:22:42.063722Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_env_feedback(S,A):\n",
    "    if A=='right':\n",
    "        if S==N_STATES-2:\n",
    "            S_='terminal'\n",
    "            R=5\n",
    "        else:\n",
    "            S_=S+1 \n",
    "            R=1 \n",
    "    else:\n",
    "        S_=S if S==0 else S-1 \n",
    "        R=0 \n",
    "    return S_,R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:22:42.079712Z",
     "start_time": "2020-06-01T02:22:42.071710Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_env(S,episode,step_counter):\n",
    "    env_list=['-']*(N_STATES-1)+['T']\n",
    "    if S=='terminal':\n",
    "        print(f\"\\rEpisode:{episode},total_step:{step_counter}\")\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        env_list[S]='o'\n",
    "        print(f\"\\r{''.join(env_list)}\",end=\"\")\n",
    "        time.sleep(FRESH_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:22:42.087713Z",
     "start_time": "2020-06-01T02:22:42.079712Z"
    }
   },
   "outputs": [],
   "source": [
    "def q_train():\n",
    "    q_table=build_table(N_STATES,ACTIONS)\n",
    "    for episode in range(1,MAX_EPISODES+1):\n",
    "        S,step_counter,is_terminal=0,0,False \n",
    "        while not is_terminal:\n",
    "            A=choose_action(S,q_table)\n",
    "            S_,R=get_env_feedback(S,A)\n",
    "            q_predict=q_table.loc[S,A]\n",
    "            if S_=='terminal':\n",
    "                q_target=R \n",
    "                is_terminal=True \n",
    "            else:\n",
    "                q_target=R+GAMMA*q_table.iloc[S_,:].max()\n",
    "            q_table.loc[S,A]+=ALPHA*(q_target-q_predict)\n",
    "            S=S_ \n",
    "            step_counter+=1\n",
    "            update_env(S,episode,step_counter)\n",
    "    return q_table\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:23:28.674515Z",
     "start_time": "2020-06-01T02:22:42.087713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1,total_step:19\n",
      "Episode:2,total_step:5\n",
      "Episode:3,total_step:5\n",
      "Episode:4,total_step:5\n",
      "Episode:5,total_step:5\n",
      "Episode:6,total_step:5\n",
      "Episode:7,total_step:5\n",
      "Episode:8,total_step:5\n",
      "Episode:9,total_step:5\n",
      "Episode:10,total_step:5\n",
      "Episode:11,total_step:5\n",
      "Episode:12,total_step:7\n",
      "Episode:13,total_step:5\n",
      "\n",
      "Q_table:\n",
      "       left     right\n",
      "0  0.009000  1.348803\n",
      "1  0.025273  1.420445\n",
      "2  0.009000  1.833672\n",
      "3  0.148685  2.498905\n",
      "4  0.025273  3.729067\n",
      "5  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "q_table=q_train()\n",
    "print(\"\\r\\nQ_table:\")\n",
    "print(q_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bita5f53f9b60c0490aa934da503dc99db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
