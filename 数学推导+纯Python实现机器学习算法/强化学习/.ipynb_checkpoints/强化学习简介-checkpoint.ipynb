{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T02:36:55.253055Z",
     "start_time": "2020-06-01T02:36:55.248527Z"
    }
   },
   "source": [
    "从整个机器学习的任务划分上来看，机器学习可以分为有监督学习、有监督和半监督学习以及强化学习，而我们之前一直谈论的图像、文本等深度学习的应用都属于监督学习范畴。自编码器和生成式对抗网络可以算在无监督深度学习范畴内。最后就只剩下强化学习了。但是我们这是深度学习的笔记，为什么要把强化学习单独拎出来讲一下呢？因为强化学习发展到现在，早已结合了神经网络迸发出新的活力，强化学习结合深度学习已经形成了深度强化学习(Deep Reinforcement Learning)这样的新领域，因为强化学习和深度学习之间的关系以及其本身作为人工智能的一个重要方向，我们都是有必要在系列笔记里体现一下的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "强化学习跟此前的监督学习有着本质的区别：\n",
    "> 监督学习是**训练模型特征到标签的映射关系**，而强化学习的学习过程却是一种**从无到有的过程**。简单来说，强化学习是让计算机实现从一开始什么都不懂，经过**不断尝试和试错找到规律达到目的**这样的一个过程。强化学习的主体与环境基于离散的时间步长相作用。在每一个时间 t，主体接收到一个观测Ot，通常其中包含奖励Rt。然后，它从允许的集合中选择一个动作At，然后送出到环境中去。环境则变化到一个新的状态 St+1，然后决定了和这个变化  (St,At,St+1)相关联的奖励Rt+1。**强化学习主体的目标，是得到尽可能多的奖励**。**主体选择的动作是其历史的函数，它也可以选择随机的动作。** 可以看到**状态(State)、动作(Action)和奖励(Reward)**是强化学习的三个核心概念。\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/20200601102849744.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**传统的强化学习算法**\n",
    "> Q-Learning算法、Sarsa算法、Policy Gradients算法、蒙特卡洛树搜索等算法。\n",
    ">\n",
    "> 强化学习算法根据以**策略为中心**还是**以值函数最优**可以分为两大类，策略优化方法和动态规划方法。\n",
    "![]( https://pic2.zhimg.com/80/v2-6da51de9c97aa14de84c27c22cdc6895_1440w.jpg)\n",
    "**当下结合了深度学习的强化学习算法**\n",
    "> 深度Q网络(DQN)，以及结合神经网络之后的深度强化学习这一整个领域。\n",
    "\n",
    "**深度强化学习的核心框架：**\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/2020060110320239.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0lfYW1fYV9idWdlcg==,size_16,color_FFFFFF,t_70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bita5f53f9b60c0490aa934da503dc99db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
